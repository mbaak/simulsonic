{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdgym import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthsonic.models.kde_utils import kde_smooth_peaks_1dim, kde_smooth_peaks\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03',\n",
    "       'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
    "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
    "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_car_01_cat', 'ps_car_02_cat',\n",
    "       'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat',\n",
    "       'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat',\n",
    "       'ps_car_11_cat', 'ps_car_11', 'ps_calc_04',\n",
    "       'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09',\n",
    "       'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
    "       'ps_calc_19_bin', 'ps_calc_20_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import TreeSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore, ExhaustiveSearch, PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # learn graph structure \n",
    "    est = TreeSearch(df, root_node=df.columns[0])\n",
    "    dag = est.estimate(class_node='ps_ind_02_cat', estimator_type=\"tan\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # alternative graph structure \n",
    "    est2 = TreeSearch(df, root_node=df.columns[0])\n",
    "    dag = est2.estimate(estimator_type=\"chow-liu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    est = HillClimbSearch(df, use_cache=True)\n",
    "    dag = est.estimate(start_dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    est = PC(df)\n",
    "    dag = est.estimate(start_dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(dag, with_labels=True, arrowsize=30, node_size=800, alpha=0.3, font_weight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = dag.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import BayesianEstimator\n",
    "\n",
    "# there are many choices of parametrization, here is one example\n",
    "model = BayesianModel(dag.edges())\n",
    "model.fit(df, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = sorted(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train-test sample.\n",
    "# the test sample is used to calibrate the output of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(data, np.ones(data.shape[0]), test_size=0.35,\n",
    "                                                        random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=MLPClassifier(random_state=0, max_iter=1000, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=2)\n",
    "\n",
    "if True:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=250,\n",
    "        reg_lambda=1,\n",
    "        gamma=0,\n",
    "        max_depth=9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argspecs = inspect.getfullargspec(clf.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_weight = 'sample_weight' in argspecs.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_one = len(X1_train)\n",
    "n_zero = n_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.sampling import BayesianModelSampling\n",
    "\n",
    "# sample data from BN\n",
    "\n",
    "#np.random.seed(seed)\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "df_data = inference.forward_sample(size=n_zero, return_type='dataframe')\n",
    "\n",
    "#df_data.columns = [int(c) for c in df_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_train = df_data[columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros(n_zero)\n",
    "ones = np.ones(n_one)\n",
    "\n",
    "yy = np.concatenate([zeros, ones], axis = 0)\n",
    "XX = np.concatenate([X0_train, X1_train], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the probabilities, using the test sample and a new null sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = inference.forward_sample(size=500000, return_type='dataframe', seed=10)\n",
    "\n",
    "if False:\n",
    "    df_data.columns = [int(c) for c in df_data.columns]\n",
    "    X = df_data[sorted(df_data.columns)].values\n",
    "X0_test = df_data[columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X0_test)[:, 1]\n",
    "p2 = clf.predict_proba(X1_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p0), len(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 200\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=nbins, range=(0,1), alpha=0.5, log=True, density=True) \n",
    "plt.hist(p2, bins=nbins, range=(0,1), alpha=0.5, log=True, density=True); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 200\n",
    "binning = np.linspace(0, 1, nbins+1)\n",
    "\n",
    "hist_p0, bin_edges = np.histogram(p0, binning)\n",
    "hist_p1, bin_edges = np.histogram(p2, binning)\n",
    "\n",
    "def poisson_uncertainty(n):\n",
    "    sigman = np.sqrt(n)\n",
    "    # correct poisson counts of zero.\n",
    "    sigman[sigman == 0] = 1.\n",
    "    return sigman\n",
    "\n",
    "def fraction_and_uncertainty(a, b, sigma_a, sigma_b):\n",
    "    frac_a = a / (a + b)\n",
    "    frac_b = b / (a + b)\n",
    "    sigma_fa2 = np.power(frac_b * sigma_a, 2) / np.power(a + b, 2)  +  np.power(frac_a * sigma_b, 2) / np.power(a + b, 2)\n",
    "    return frac_a, np.sqrt(sigma_fa2)\n",
    "\n",
    "rest_p0 = np.sum(hist_p0) - hist_p0\n",
    "rest_p1 = np.sum(hist_p1) - hist_p1\n",
    "\n",
    "sigma_bin0 = poisson_uncertainty(hist_p0)\n",
    "sigma_rest0 = poisson_uncertainty(rest_p0)\n",
    "\n",
    "sigma_bin1 = poisson_uncertainty(hist_p1)\n",
    "sigma_rest1 = poisson_uncertainty(rest_p1)\n",
    "\n",
    "frac0, sigma_frac0 = fraction_and_uncertainty(hist_p0, rest_p0, sigma_bin0, sigma_rest0)\n",
    "frac1, sigma_frac1 = fraction_and_uncertainty(hist_p1, rest_p1, sigma_bin1, sigma_rest1)\n",
    "\n",
    "p1calib, sigma_p1calib = fraction_and_uncertainty(frac1, frac0, sigma_frac1, sigma_frac0)\n",
    "\n",
    "sample_weight = 1 / (sigma_p1calib * sigma_p1calib)\n",
    "\n",
    "sample_weight /= min(sample_weight)\n",
    "\n",
    "sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.40000e-05 * 6207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(hist_p0[-1]) / hist_p0[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(bin_centers, p1calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we recalibrate per probability bin. NO interpolation (not valid in highest bin)\n",
    "\n",
    "#hist_p0, bin_edges = np.histogram(p0, bins=nbins, range=(0, 1))\n",
    "#hist_p1, bin_edges = np.histogram(p2, bins=nbins, range=(0, 1)) #### !!!! p2\n",
    "bin_centers = bin_edges[:-1] + 0.5/nbins\n",
    "\n",
    "hnorm_p0 = hist_p0 / sum(hist_p0)\n",
    "hnorm_p1 = hist_p1 / sum(hist_p1)\n",
    "hnorm_sum = hnorm_p0 + hnorm_p1\n",
    "p1cb = np.divide(hnorm_p1, hnorm_sum, out=np.zeros_like(hnorm_p1), where=hnorm_sum != 0)\n",
    "# self.p1cb = p1cb, bin_centers\n",
    "\n",
    "# use isotonic regression to smooth out potential fluctuations in the p1 values\n",
    "# isotonic regression assumes that p1 can only be a rising function.\n",
    "# I’m assuming that if a classifier predicts a higher probability, the calibrated probability\n",
    "# will also be higher. This may not always be right, but I think generally it is a safe one.\n",
    "iso_reg = IsotonicRegression(y_min=0, y_max=1).fit(bin_centers, p1calib, sample_weight)\n",
    "p1pred = iso_reg.predict(bin_centers)\n",
    "\n",
    "p1f_ = interpolate.interp1d(bin_edges[:-1], p1pred, kind='previous', bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "p1pred = p1f_(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1pred[-1] = 0.9998389328412737\n",
    "\n",
    "p1f_ = interpolate.interp1d(bin_edges[:-1], p1pred, kind='previous', bounds_error=False, fill_value=\"extrapolate\")\n",
    "\n",
    "p1pred = p1f_(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(bin_centers, p1cb)\n",
    "plt.plot(bin_centers, p1pred)\n",
    "plt.plot(bin_centers, bin_centers)\n",
    "#plt.plot(bin_centers, p1lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.9,1,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = p1f_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "#plt.plot(bin_centers, p1cb)\n",
    "plt.plot(x, pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp1 = p1f_(0.999)\n",
    "maxp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxp2 = p1f_(0.991)\n",
    "maxp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight = maxp1 / (1. - maxp1)\n",
    "max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = p1f_(0.991) / (1. - p1f_(0.991))\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation - part 1: check if reweighting works okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.sampling import BayesianModelSampling\n",
    "\n",
    "# sample data from BN\n",
    "inference = BayesianModelSampling(model)\n",
    "\n",
    "df_data = inference.forward_sample(size=250000, return_type='dataframe', seed=1)\n",
    "\n",
    "#df_data.columns = [int(c) for c in df_data.columns]\n",
    "\n",
    "X = df_data[columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X)[:, 1]\n",
    "nominator = p1f_(p0)\n",
    "denominator = 1 - nominator\n",
    "weight = np.divide(nominator, denominator, out=np.ones_like(nominator), where=denominator != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = weight == max_weight\n",
    "same = weight != max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(weight[same]), np.sum(weight[keep]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (250000 - np.sum(weight[same])) / np.sum(weight[keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight[keep] = weight[keep] * ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(weight[weight < 20], bins=100, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight = max(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_weight / (1 + max_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, sample_weights = self._sample_no_transform(n_samples, random_state)\n",
    "pop = np.asarray(range(X.shape[0]))\n",
    "probs = weight/np.sum(weight)\n",
    "sample = choices(pop, probs, k=X.shape[0])\n",
    "Xtrans = X[sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(Xtrans)[:, 1]\n",
    "p2 = clf.predict_proba(X1_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=200, range=(0,1), alpha=0.5, density=True, log=True) #, weights=weight)#, log=True)\n",
    "plt.hist(p2, bins=200, range=(0,1), alpha=0.5, density=True, log=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(p0, bins=100, range=(0,1), alpha=0.5, density=True, log=True) #, weights=weight)#, log=True)\n",
    "plt.hist(p2, bins=100, range=(0,1), alpha=0.5, density=True, log=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation - part 2: plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.hist(X[:, i], bins=100, range=(0,1), alpha=0.5, density=True)#, log=True)\n",
    "plt.hist(X1_test[:, i], bins=100, range=(0,1), alpha=0.5, density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation part 3: check number of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = inference.forward_sample(size=500000, return_type='dataframe', seed=2)\n",
    "#df_data.columns = [int(c) for c in df_data.columns]\n",
    "X10k = df_data[columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = clf.predict_proba(X10k)[:, 1]\n",
    "nominator = p1f_(p0)\n",
    "denominator = 1 - nominator\n",
    "weight = np.divide(nominator, denominator, out=np.ones_like(nominator), where=denominator != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.asarray(range(X10k.shape[0]))\n",
    "probs = weight/np.sum(weight)\n",
    "sample = choices(pop, probs, k=X10k.shape[0])\n",
    "Xtrans = X10k[sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u, c = np.unique(Xtrans, axis=0, return_counts=True)\n",
    "u, c = np.unique(Xtrans, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.sort(c)[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(data, axis=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = np.sort(c)[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.bar(list(range(40)), c2[:40], alpha=0.5)\n",
    "plt.bar(list(range(40)), counts[:40], alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "plt.bar(list(range(40)), c2[:40], alpha=0.5)\n",
    "plt.bar(list(range(40)), counts[:40], alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sdgym import benchmark\n",
    "from sdgym import load_dataset\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from synthsonic.models.kde_copula_nn_pdf import KDECopulaNNPdf\n",
    "from synthsonic.models.categorical_utils import categorical_round, vec_translate, categorical_frequency_mapping, \\\n",
    "            categorical_frequency_inverse_mapping, encode_one_hot, decode_one_hot\n",
    "from timeit import default_timer as timer\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(Xtrans)\n",
    "df.to_csv('test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KDECopulaNNPdf_RoundCategorical(real_data, categorical_columns, ordinal_columns, times=None):\n",
    "    df = pd.read_csv('test.csv')\n",
    "    data = df.values[:25000]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_times = []\n",
    "alarm_thing = partial(KDECopulaNNPdf_RoundCategorical)\n",
    "alarm_thing.__name__ = KDECopulaNNPdf_RoundCategorical.__name__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_scores = benchmark(synthesizers=[alarm_thing], datasets=['alarm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    alarm_scores = benchmark(synthesizers=[alarm_thing], datasets=['alarm'])\n",
    "    alarm_scores.drop(columns=['timestamp'], inplace=True)\n",
    "    exec_time = ['N/A'] * 9 + [round(np.mean(alarm_times), 2)]\n",
    "    alarm_scores['alarm/exec_time(s)'] = exec_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
